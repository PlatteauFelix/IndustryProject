{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUkVOcib37Vk"
   },
   "source": [
    "# Preparation\n",
    "\n",
    "* label images in vott\n",
    "* make dataset in roboflow\n",
    "* upload labelled images to dataset\n",
    "* export dataset to yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: google collab training\n",
    "When working in google colab: change runtime type in google collab to GPU in hardware accelerator (arrow next to connect in the right corner -> view resources -> change runtime type)\n",
    "\n",
    "Note: you cannot run google collab indefinitely, normally max 12 hours and you cannot be idle more than 3 hours, also don't close your browser else everything is gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B8tovxMsPzfP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2270111566349575632\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which GPU u got, most of the time it's a K80\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scroll down to train your model\n",
    "When training is done you can export your model's weights below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model\n",
    "Export your model's weights for future use\n",
    "\n",
    "Note: you may have to change the path to latest run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('./runs/train/exp/weights/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: local training\n",
    "When working local (windows 10) and have a nvidia GPU: make a venv + install nvidia cuda + install pytorch for cuda\n",
    "\n",
    "https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m venv venv\n",
    "# .\\venv\\Scripts\\activate\n",
    "# pip install ipykernel\n",
    "# python -m ipykernel install --user --name venv --display-name \"Python my venv\"\n",
    "# (optional) reload window\n",
    "# select venv as kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plVrE3xqyifv"
   },
   "outputs": [],
   "source": [
    "# this can take a while and has no output in jupter notebook during install. If you want output install in terminal\n",
    "%pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x000002D39A7535B0>\n",
      "NVIDIA GeForce GTX 1660 Ti\n",
      "(7, 5)\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce GTX 1660 Ti', major=7, minor=5, total_memory=6143MB, multi_processor_count=24)\n"
     ]
    }
   ],
   "source": [
    "# check if pytorch detects your GPU\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_capability(0))\n",
    "print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Next sections is for google collab AND local training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTleuStd5go5"
   },
   "source": [
    "### Pull yolov5 enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QKjIKT440w1"
   },
   "outputs": [],
   "source": [
    "#clone YOLOv5 and \n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%pip install -r yolov5\\requirements.txt\n",
    "%pip install roboflow\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOpF0WhQ5NBK"
   },
   "source": [
    "### (optional) install wandb to view perfomance while model is training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7kk05Jfp5K1i"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\felix\\Documents\\Howest\\2S2\\TESTING\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mplatteaufelix\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights & Biases  (optional)\n",
    "%pip install -q wandb\n",
    "import wandb\n",
    "wandb.login()\n",
    "# don't forget to authorize login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utJMGl5MKr7i"
   },
   "source": [
    "### Pull dataset images\n",
    "Generate new version in roboflow and export to yolov5 pytorch and paste download code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9RMurKfFKqf9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'roboflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\felix\\Documents\\Howest\\2S2\\TESTING\\DLC_AI_TEMPLATE.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/felix/Documents/Howest/2S2/TESTING/DLC_AI_TEMPLATE.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mroboflow\u001b[39;00m \u001b[39mimport\u001b[39;00m Roboflow\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felix/Documents/Howest/2S2/TESTING/DLC_AI_TEMPLATE.ipynb#ch0000011?line=1'>2</a>\u001b[0m rf \u001b[39m=\u001b[39m Roboflow(api_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlBeRX0ddTHzL4Dk8rJ1l\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felix/Documents/Howest/2S2/TESTING/DLC_AI_TEMPLATE.ipynb#ch0000011?line=2'>3</a>\u001b[0m project \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mworkspace(\u001b[39m\"\u001b[39m\u001b[39mdlc-ai\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mproject(\u001b[39m\"\u001b[39m\u001b[39mlabelled-frames\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'roboflow'"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"lBeRX0ddTHzL4Dk8rJ1l\")\n",
    "project = rf.workspace(\"dlc-ai\").project(\"labelled-frames\")\n",
    "dataset = project.version(2).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNjv1vMpK3gF"
   },
   "source": [
    "### Train model\n",
    "* choose a model https://pytorch.org/hub/ultralytics_yolov5/\n",
    "* most of the time yolov5s or yolov5m is good enough\n",
    "* start with 300 epoch if you can\n",
    "* set image size at resolution of photo when it needs to detect small objects\n",
    "* set batch at -1 to use max allowed\n",
    "* (optional) if you've installed wandb: check progress at https://wandb.ai/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cwF9kSqK5Ps"
   },
   "outputs": [],
   "source": [
    "!python train.py --img 1080 --batch -1 --epochs 300 --data labelled-frames-1/data.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-gxs8OWUe9y"
   },
   "outputs": [],
   "source": [
    "# when training is done: plot results\n",
    "from utils.plots import plot_results \n",
    "plot_results('path/to/results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVFs8pFlTwcX"
   },
   "source": [
    "### Test\n",
    "(local) test model on test images in dataset\n",
    "\n",
    "(google collab) Can be tested in the cloud but also local if you export model from google collab, see method 1: export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysFNoCRFTuSh"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('./runs/labelled-frames-1/test/images*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpJvFXaYNOwz"
   },
   "source": [
    "### Detect\n",
    "can take a while\n",
    "\n",
    "(local) change link to source of file you want to detect and run\n",
    "\n",
    "(google collab) upload video (, change path) and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJVGvJa5NTn6"
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/exp/weights/best.pt --img 1080 --source video.mp4"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DLC_AI_TEMPLATE.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "143b891882f9f973a558471fc357750d5def766f83de42b103bfe17162546487"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
